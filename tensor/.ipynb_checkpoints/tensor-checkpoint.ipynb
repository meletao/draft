{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759ec948-159b-4439-8046-4a66d3bf5db9",
   "metadata": {},
   "source": [
    "# Tensor\n",
    "\n",
    "`Tensor` is a Python class in the `torch` library to store numerical data and perform numerical operations. If you are already familiar with `ndarray` class from the `numpy` library, they share alot as far as the APIs naming convention is concerned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc2d6ad-e9ad-4f25-ae53-ae37305ef005",
   "metadata": {},
   "source": [
    "# Inheritance Chain\n",
    "\n",
    "For anyone interested to see the inheritance chain of `tensor` and `ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6676b0c6-9c74-4d76-8ed9-852dc4cc8e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor inheritance: [<class 'torch.Tensor'>, <class 'torch._C.TensorBase'>, <class 'object'>]\n",
      "ndarray inheritance: [<class 'numpy.ndarray'>, <class 'object'>]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Inheritance\n",
    "print(f\"tensor inheritance: {torch.tensor([]).__class__.mro()}\")\n",
    "print(f\"ndarray inheritance: {np.array([]).__class__.mro()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7f380b-9ace-41ac-8d4a-d08b9fc13775",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a57ba12d-39e0-4e6f-ae24-56590540f815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor from list: tensor([1, 2, 3])\n",
      "tensor from ndarray: tensor([1, 2, 3])\n",
      "tensor from tuple: tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# [Ankit Anand]\n",
    "# Creating/Instantiating a tensor object\n",
    "# =======================================\n",
    "\n",
    "# From python list\n",
    "t_from_list = torch.tensor([1, 2, 3])\n",
    "\n",
    "# From ndarray\n",
    "t_from_ndarray = torch.tensor(np.array([1, 2, 3]))\n",
    "\n",
    "# From python tuple\n",
    "t_from_tuple = torch.tensor((1, 2, 3))\n",
    "\n",
    "print(f\"tensor from list: {t_from_list}\")\n",
    "print(f\"tensor from ndarray: {t_from_ndarray}\")\n",
    "print(f\"tensor from tuple: {t_from_tuple}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "90037208-9d27-4c8e-8f1b-a9179dc5be5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arange: tensor([0, 2, 4])\n",
      "float arange: tensor([0., 2., 4.], dtype=torch.float16)\n",
      "linspace: tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n",
      "zeros: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "ones: tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "randn: tensor([ 1.5594,  0.2723, -0.0582,  0.3333,  0.9996, -0.1917,  0.3742,  1.6397,\n",
      "        -1.1974, -0.7569])\n",
      "randint: tensor([[16, 13],\n",
      "        [19, 16]])\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# [Ankit Anand]\n",
    "# Creating/Instantiating a tensor object\n",
    "# using tensor APIs\n",
    "# =======================================\n",
    "\n",
    "t_with_arange = torch.arange(0, 5, 2) # (start, end, step)\n",
    "float_t_with_arange = torch.arange(0, 5, 2, dtype=torch.float16)\n",
    "t_with_linspace = torch.linspace(0, 1, 5) # (start, end, number of points)\n",
    "t_with_zeros = torch.zeros(10) # 10-tensor with all values 1\n",
    "t_with_ones = torch.ones((2, 2)) # 2X2 tensor with all values 1\n",
    "t_with_randn = torch.randn(10) # 10-tensor with random values normally distribution (mean=0, std=1)\n",
    "t_with_randint = torch.randint(10, 20, (2, 2)) # 2X2 tensor of random integers between 10 and 20\n",
    "\n",
    "print(f\"arange: {t_with_arange}\")\n",
    "print(f\"float arange: {float_t_with_arange}\")\n",
    "print(f\"linspace: {t_with_linspace}\")\n",
    "print(f\"zeros: {t_with_zeros}\")\n",
    "print(f\"ones: {t_with_ones}\")\n",
    "print(f\"randn: {t_with_randn}\")\n",
    "print(f\"randint: {t_with_randint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afd2a43-75ef-47f2-8fa1-c82195489298",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9762ddca-f12a-4c0e-b5d6-e7683cbefdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19])\n",
      "t[5]: 5, type:<class 'torch.Tensor'>\n",
      "t[5:8]: tensor([5, 6, 7])\n",
      "t[5:]: tensor([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
      "t[:4]: tensor([0, 1, 2, 3])\n",
      "t[::2]: tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])\n",
      "==================================================\n",
      "T: tensor([[0.4380, 0.0659, 0.1876, 0.0483],\n",
      "        [0.1423, 0.6262, 0.2688, 0.1409],\n",
      "        [0.1073, 0.9776, 0.5134, 0.8360]])\n",
      "T[[0,2]]: 0.1875976324081421\n",
      "T[:,3]: tensor([0.0483, 0.1409, 0.8360])\n",
      "T[1,:]: tensor([0.1423, 0.6262, 0.2688, 0.1409])\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# [Ankit Anand]\n",
    "# Tensor object allows indexing to get the\n",
    "# element(s) of interest.\n",
    "# =======================================\n",
    "\n",
    "t = torch.arange(20)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"t[5]: {t[5]}, type:{type(t[5])}\") # Element at index 5\n",
    "print(f\"t[5:8]: {t[5:8]}\") # From element at index 5 to element at index 7\n",
    "print(f\"t[5:]: {t[5:]}\") # From element at index 5 to the end\n",
    "print(f\"t[:4]: {t[:4]}\") # From element at index 0 till the element at index 3\n",
    "print(f\"t[::2]: {t[::2]}\") # Element at index 0, 2, 4, ...\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "T = torch.rand((3, 4))\n",
    "print(f\"T: {T}\")\n",
    "print(f\"T[[0,2]]: {T[0,2]}\") # Element at index (0, 2)\n",
    "print(f\"T[:,3]: {T[:,3]}\") # Column at index 3\n",
    "print(f\"T[1,:]: {T[1,:]}\") # Row at index 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c06566-4ddf-4158-a17e-87cc45f07067",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "Indexing will always return a `tensor` object.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0725cd-112c-47c8-85d1-9c30c4dbc2c0",
   "metadata": {},
   "source": [
    "# Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f98a47d0-23d0-4697-a04d-ad8af67be142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: tensor([[0.3733, 0.3737, 0.4587, 0.5322],\n",
      "        [0.6161, 0.6674, 0.3022, 0.3378],\n",
      "        [0.6985, 0.9030, 0.7034, 0.9529]])\n",
      "Updated T: tensor([[ 0.3733,  0.3737,  0.4587, 10.0000],\n",
      "        [ 0.6161,  0.6674,  0.3022, 10.0000],\n",
      "        [ 0.6985,  0.9030,  0.7034, 10.0000]])\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# [Ankit Anand]\n",
    "# Index it and then assign whatever value\n",
    "# you want to.\n",
    "# =======================================\n",
    "T = torch.rand((3, 4))\n",
    "print(f\"T: {T}\")\n",
    "\n",
    "T[:,3] = 10.0 # Make elements of column (index 3) 10.0\n",
    "\n",
    "print(f\"Updated T: {T}\") # Column at index 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45793ff0-6a4a-411d-b908-4f19f71e1647",
   "metadata": {},
   "source": [
    "# Transformation\n",
    "\n",
    "Transformation simply means to take `tensor` object(s) and returns a new tensor (transformed tensor).\n",
    "\n",
    "Performing `tensor` operation is much faster due to C/C++ loop and GPU acceleration than using python `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a6c79160-012e-4e84-8203-68a7245daf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================Unary=========================\n",
      "t: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "sin: tensor([ 0.0000,  0.8415,  0.9093,  0.1411, -0.7568, -0.9589, -0.2794,  0.6570,\n",
      "         0.9894,  0.4121])\n",
      "exp: tensor([1.0000e+00, 2.7183e+00, 7.3891e+00, 2.0086e+01, 5.4598e+01, 1.4841e+02,\n",
      "        4.0343e+02, 1.0966e+03, 2.9810e+03, 8.1031e+03])\n",
      "=========================Binary=========================\n",
      "t1: tensor([1, 2, 3]), t2: tensor([3, 4, 3])\n",
      "+: tensor([4, 6, 6])\n",
      "-: tensor([-2, -2,  0])\n",
      "*: tensor([3, 8, 9])\n",
      "/: tensor([0.3333, 0.5000, 1.0000])\n",
      "//: tensor([0, 0, 1])\n",
      "**: tensor([ 1, 16, 27])\n",
      "%: tensor([1, 2, 0])\n",
      ">: tensor([False, False, False])\n",
      "concatentated: tensor([1, 2, 3, 3, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# [Ankit Anand]\n",
    "# Unary Op: Operation that takes one\n",
    "# input and returns a transformed tensor.\n",
    "# =======================================\n",
    "\n",
    "t = torch.arange(10)\n",
    "sin_t = torch.sin(t) # In radian\n",
    "cos_t = torch.cos(t) # In radian\n",
    "tan_t = torch.tan(t) # In radian\n",
    "\n",
    "exp_t = torch.exp(t)\n",
    "ln_t = torch.log(t) # Base is `e`\n",
    "log_t = torch.log10(t) # Base if `10`\n",
    "\n",
    "print(\"=\"*25 + \"Unary\" + \"=\"*25)\n",
    "\n",
    "print(f\"t: {t}\")\n",
    "print(f\"sin: {sin_t}\")\n",
    "print(f\"exp: {exp_t}\")\n",
    "\n",
    "# =======================================\n",
    "# [Ankit Anand]\n",
    "# Binary Op: Operation that takes two\n",
    "# inputs and returns a transformed tensor.\n",
    "# =======================================\n",
    "t1 = torch.tensor([1, 2, 3])\n",
    "t2 = torch.tensor([3, 4, 3])\n",
    "\n",
    "print(\"=\"*25 + \"Binary\" + \"=\"*25)\n",
    "\n",
    "print(f\"t1: {t1}, t2: {t2}\")\n",
    "print(f\"+: {t1 + t2}\")\n",
    "print(f\"-: {t1 - t2}\")\n",
    "print(f\"*: {t1 * t2}\")\n",
    "print(f\"/: {t1 / t2}\")\n",
    "print(f\"//: {t1 // t2}\") # Floor division\n",
    "print(f\"**: {t1 ** t2}\") # Power\n",
    "print(f\"%: {t1 % t2}\") # Remainder\n",
    "print(f\">: {t1 > t2}\") # Returns tensor with boolean. Similary for other comparision ==, >=, <, <=, !=\n",
    "\n",
    "concatenated_t = torch.cat((t1, t2))\n",
    "print(f\"concatentated: {concatenated_t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56e322b-880b-4a55-989b-185ad7d6f5e1",
   "metadata": {},
   "source": [
    "# Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "13f3fbb7-3e40-45cf-9690-5fea3e0c47cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Number of elements: 10\n",
      "Shape of the tensor: torch.Size([10])\n",
      "Size of the tensor: torch.Size([10])\n",
      "==================================================\n",
      "Tensor: tensor([[0.9458, 0.9106, 0.9307, 0.8452],\n",
      "        [0.0425, 0.7354, 0.5908, 0.0605],\n",
      "        [0.5986, 0.4546, 0.8975, 0.6519]], dtype=torch.float16)\n",
      "Number of elements: 12\n",
      "Shape of the tensor: torch.Size([3, 4])\n",
      "Size of the tensor: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# [Ankit Anand]\n",
    "# Properties of a tensor object\n",
    "# =======================================\n",
    "\n",
    "t = torch.arange(10) # [0, 1, 2, ..., 9]\n",
    "print(f\"Tensor: {t}\")\n",
    "print(f\"Number of elements: {t.numel()}\")\n",
    "print(f\"Shape of the tensor: {t.shape}\")\n",
    "print(f\"Size of the tensor: {t.size()}\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "T = torch.rand((3, 4), dtype=torch.float16) # 3X4 tensor with random values\n",
    "print(f\"Tensor: {T}\")\n",
    "print(f\"Number of elements: {T.numel()}\") # ndarray does not have this\n",
    "print(f\"Shape of the tensor: {T.shape}\")\n",
    "print(f\"Size of the tensor: {T.size()}\") # ndarray has .size not .size()\n",
    "\n",
    "# `tensor` differ from `ndarray` with how shape and size are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2964044-c993-4f5d-bba6-24a5f824b025",
   "metadata": {},
   "source": [
    "# Reshape\n",
    "\n",
    "The `reshape()` method is heavily used in the deep learning architectures. Thus it is important to understand how it works.\n",
    "\n",
    "Say, you have a $2 \\times 3$ tensor $t$ and you want to reshape it to $3 \\times 2$. This is only possible if they have same number of elements (`.numel()`).\n",
    "\n",
    "The tensor to be reshaped is first interpreted as a one-dimensional sequence in row-major (C-style) order:\n",
    "$[t[0,0], t[0,1], t[0,2], t[1,0], t[1,1], t[1,2]]$\n",
    "\n",
    "The values are then placed sequentially (row-major) into the new $3 \\times 2$ shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "43a91fa7-33f1-44a5-8576-f011e118d9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor: tensor([[0.6493, 0.2648, 0.6163],\n",
      "        [0.8383, 0.3791, 0.4962]])\n",
      "reshaped tensor: tensor([[0.6493, 0.2648],\n",
      "        [0.6163, 0.8383],\n",
      "        [0.3791, 0.4962]])\n",
      "reshaped tensor (auto): tensor([[0.6493, 0.2648],\n",
      "        [0.6163, 0.8383],\n",
      "        [0.3791, 0.4962]])\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# [Ankit Anand]\n",
    "# Reshaping a tensor object\n",
    "# =======================================\n",
    "\n",
    "t = torch.rand((2, 3))\n",
    "t_reshaped = t.reshape(3, 2) # It creates a `new` reshaped tensor\n",
    "t_reshaped_auto = t.reshape(3, -1) # It automatically estimates the shape based on numel\n",
    "\n",
    "print(f\"tensor: {t}\")\n",
    "print(f\"reshaped tensor: {t_reshaped}\")\n",
    "print(f\"reshaped tensor (auto): {t_reshaped_auto}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df53b3f4-4941-486e-b2d8-4e5013605637",
   "metadata": {},
   "source": [
    "# Broadcasting\n",
    "\n",
    "So far, we have seen that most tensor operations are performed elementwise. In the case of a unary operation, each element of a tensor is transformed independently. In the case of a binary operation, the transformation is applied to corresponding elements from two tensors of the same shape.\n",
    "\n",
    "However, there are situations where operations can still be applied to tensors of different shapes. The mechanism that makes this possible is called **broadcasting**.\n",
    "\n",
    "It introduces an implicit intermediate step where one or both tensors are expanded to compatible shapes. This hidden step is the source of many subtle and hard-to-debug errors if broadcasting rules are not properly understood.\n",
    "\n",
    "Here is the broadcating rule: \n",
    "1. Align shapes from the right\n",
    "2. For each dimension: Dimensions are compatible if they are equal, or one of them is 1\n",
    "3. If compatible, the tensor with size 1 is broadcast (virtually repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f63f66b7-8ce1-480f-9bcb-068fd1f068b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1: tensor([[1, 2, 1, 0],\n",
      "        [2, 3, 1, 2]])\n",
      "t2: tensor([[1, 2, 0, 0]])\n",
      "t3: tensor([[2],\n",
      "        [1]])\n",
      "t1 + t2: tensor([[2, 4, 1, 0],\n",
      "        [3, 5, 1, 2]])\n",
      "t1 + t3: tensor([[3, 4, 3, 2],\n",
      "        [3, 4, 2, 3]])\n",
      "t1 + t4: tensor([[4, 5, 2, 1],\n",
      "        [5, 6, 2, 3]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mt1 + t3: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt1\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39mt3\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mt1 + t4: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt1\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39mt4\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mt1 + t5: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mt1\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43m+\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mt5\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# [Ankit Anand]\n",
    "# Broadcasting\n",
    "# =======================================\n",
    "\n",
    "# Example 1\n",
    "t1 = torch.randint(0, 5, (2, 4)) # 2X4\n",
    "t2 = torch.randint(0, 5, (1, 4)) # 1X4\n",
    "t3 = torch.randint(0, 5, (2, 1)) # 2X1\n",
    "t4 = torch.randint(0, 5, (4, )) # 4\n",
    "t5 = torch.randint(0, 5, (4, 1)) # 4X1\n",
    "\n",
    "print(f\"t1: {t1}\")\n",
    "print(f\"t2: {t2}\")\n",
    "print(f\"t3: {t3}\")\n",
    "\n",
    "\"\"\" \n",
    "Mechanism\n",
    "\n",
    "====== t1 + t2 ======\n",
    "t1: 2 4\n",
    "t2: 1 4 <- t1.shape[-1] = 4 matches with t2.shape[-1] = 4\n",
    "t2: 1 4 <- t1.shape[-2] = 2 does not match with t2.shape[-2] = 1 (but it is 1 so possibility of broadcast)\n",
    "t2: 2 4 <- Virtually repeat along vertically to make it 2 4 => Apply binary operation!!\n",
    "\n",
    "====== t1 + t3 ======\n",
    "t1: 2 4\n",
    "t3: 2 1 => Virtually repeat horizontally to make it 2 4 => Apply binary operation!!\n",
    "\n",
    "====== t1 + t4 ======\n",
    "t1: 2 4\n",
    "t4:   4 <- Matches\n",
    "t4: 1 4 <- Understood as 1\n",
    "t4: 2 4 <- Virtually Repeat => Apply binary operation!!\n",
    "\n",
    "====== t1 + t5 ======\n",
    "t1: 2 4\n",
    "t5: 4 1 <- 1 does not match 4 (but it is one so repeat)\n",
    "t5: 4 4 <- Shapes do not match => Throw error\n",
    "\"\"\"\n",
    "print(f\"t1 + t2: {t1 + t2}\")\n",
    "print(f\"t1 + t3: {t1 + t3}\")\n",
    "print(f\"t1 + t4: {t1 + t4}\")\n",
    "print(f\"t1 + t5: {t1 + t5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a904cb-be1f-4d05-b036-19d897d0f487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "draft",
   "language": "python",
   "name": "draft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
